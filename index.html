<!DOCTYPE html><!--Author: Pranav Rajpurkar 2016--><html><head><meta charset="utf-8"><title>Phrase Indexed Question Answering</title><meta name="description" content="We formalize a new modular variant of current question answering tasks by enforcing complete independence of the document encoder from the question encoder. This formulation addresses a key challenge in machine comprehension by requiring a standalone representation of the document discourse. It additionally leads to a significant scalability advantage since the encoding of the answer candidate phrases in the document can be pre-computed and indexed offline for efficient retrieval. We experiment with baseline models for the new task, which achieve a reasonable accuracy but significantly underperform unconstrained QA models. We invite the QA research community to engage in Phrase-Indexed Question Answering (PIQA, pika) for closing the gap."><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.png"><link rel="image_src" type="image/png" href="/piqa-web/logo.png"><link rel="shortcut icon" href="/piqa-web/favicon.ico" type="image/x-icon"><link rel="icon" href="/piqa-web/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/piqa-web/bower_components/bootstrap/dist/css/bootstrap.min.css"><link rel="stylesheet" href="/piqa-web/stylesheets/layout.css"><link rel="stylesheet" href="/piqa-web/stylesheets/index.css"><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/piqa-web/javascripts/analytics.js"></script></head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="rightNav"><div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div><div class="collapse navbar-collapse" id="navbar"><ul class="nav navbar-nav navbar-right"><li><a href="/piqa-web/">Home</a></li></ul></div></div><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="/piqa-web/">PIQA</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle">PIQA</h1><h2 id="appSubtitle">Phrase-Indexed Question Answering</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-5"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>What is PIQA?</h2></div><p> <span><b>P</b>hrase-<b>I</b>ndexed <b>Q</b>uestion <b>A</b>nswering (PIQA) </span>is a new variant of question answering tasks with complete <i>independence </i>of the document encoder from the question encoder. This task addresses a key challenge in machine comprehension by requiring a standalone representation of the document discourse. It additionally leads to a significant scalability advantage since the encoding of the answer candidate phrases in the document can be pre-computed and indexed offline for efficient answer retrieval. We invite the QA research community to engage in Phrase-Indexed Question Answering (PIQA, pika) for closing the gap between PIQA baseline models and unconstrained QA models.</p><hr><p><b> PIQA</b> uses <a href="https://arxiv.org/abs/1607.05250">SQuAD1.1 </a>for the evaluation. For the details of PIQA and baseline models, please refer to our paper.</p><a class="btn actionBtn" href="https://arxiv.org/abs/1804.07726">PIQA paper (Seo et al. EMNLP 2018)</a><hr><p></p><div class="infoHeadline"><h2>Getting Started</h2></div><p>We've built a few resources to help you get started with the dataset.</p><p> Download a copy of the dataset (distributed under the  <a href="http://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA 4.0</a> license):<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="/piqa-web/dataset/train-v2.0.json" download>Training Set v2.0 (40 MB)</a></li><li><a class="btn actionBtn inverseBtn" href="/piqa-web/dataset/dev-v2.0.json" download>Dev Set v2.0 (4 MB)</a></li></ul></p><p>To evaluate your models, we have also made available the evaluation script we will use for official evaluation, along with a sample prediction file that the script will take as input. To run the evaluation, use <code>python evaluate-v2.0.py &lt;path_to_dev-v2.0&gt; &lt;path_to_predictions&gt;</code>.<ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/" download>Evaluation Script v2.0</a></li><li><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/bundles/0x8731effab84f41b7b874a070e40f61e2/" download>Sample Prediction File (on Dev v2.0)</a></li></ul></p><p>Once you have a built a model that works to your expectations on the dev set, you submit it to get official scores on the dev and a hidden test set. To preserve the integrity of test results, we do not release the test set to the public. Instead, we require you to submit your model so that we can run it on the test set for you. Here's a tutorial walking you through official evaluation of your model:</p><a class="btn actionBtn inverseBtn" href="https://worksheets.codalab.org/worksheets/0x8212d84ca41c4150b555a075b19ccc05/">Submission Tutorial</a><p>Because PIQA is hoho ongoing effort, we expect the dataset to evolve.</p><p>To keep up to date with major changes to the dataset, please subscribe:</p><div id="mc_embed_signup"><form class="validate" id="mc-embedded-subscribe-form" action="//google.us13.list-manage.com/subscribe/post?u=1842e6560d6e10316b4e1aaf5&amp;id=76586bdcf4" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate=""><div id="mc_embed_signup_scroll"><input class="email" id="mce-EMAIL" type="email" value="" name="EMAIL" placeholder="email address" required=""><div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_1842e6560d6e10316b4e1aaf5_76586bdcf4" tabindex="-1" value=""></div><div class="clear"><input class="button" id="mc-embedded-subscribe" type="submit" value="Subscribe" name="subscribe"></div></div></form></div><div class="infoHeadline"><h2>Have Questions?</h2></div><p> Ask us questions at our   <a href="https://groups.google.com/forum/#!forum/squad-stanford-qa">google group</a> or at <a href="mailto:pranavsr@stanford.edu">pranavsr@stanford.edu</a> and <a href="mailto:robinjia@stanford.edu">robinjia@stanford.edu</a>.</p></div><div class="infoSubheadline"><a href="https://twitter.com/share" class="twitter-share-button" data-url="https://stanford-qa.com" data-text="The Stanford Question Answering Dataset - 100,000+ questions for reading comprehension" data-via="stanfordnlp" data-size="large" data-hashtags="SQuAD">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><!-- Place this tag where you want the button to render. -->
<a class="github-button" href="https://github.com/uwnlp/piqa-web" data-icon="octicon-star" data-style="mega" data-count-href="/uwnlp/piqa-web/stargazers" data-count-api="/repos/uwnlp/piqa-web#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star uwnlp/piqa-web on GitHub">Star</a></div></div></div><div class="col-md-7"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Leaderboard</h2></div><p>PIQA tests the ability of a system to produce standalone representation of the document discourse. </p><table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>EM</th><th>F1</th></tr><tr class="human-row"><td></td><td>Human Performance<p class="institution">Stanford University</p><a href="http://arxiv.org/abs/1606.05250">(Rajpurkar & Jia et al. '18)</a></td><td>86.831</td><td>89.452</td></tr><tr><td> <p>1</p><span class="date label label-default">Oct 06, 2018</span></td><td style="word-break:break-word;">LSTM + SA<p class="institution">baseline</p><a class="link" href="https://arxiv.org/abs/1804.07726">https://arxiv.org/abs/1804.07726</a></td><td><b>49.000</b></td><td><b>59.800</b></td></tr><tr><td> <p>2</p><span class="date label label-default">Oct 06, 2018</span></td><td style="word-break:break-word;">LSTM<p class="institution">baseline</p><a class="link" href="https://arxiv.org/abs/1804.07726">https://arxiv.org/abs/1804.07726</a></td><td>46.800</td><td>57.200</td></tr><tr><td> <p>3</p><span class="date label label-default">Oct 06, 2018</span></td><td style="word-break:break-word;">TF-IDF<p class="institution">baseline</p><a class="link" href="https://arxiv.org/abs/1804.07726">https://arxiv.org/abs/1804.07726</a></td><td>3.9000</td><td>15.000</td></tr></table></div></div></div></div></div></div><nav class="navbar navbar-default navbar-static-bottom footer"><div class="container clearfix"><div class="rightNav"><div><ul class="nav navbar-nav navbar-right"><li><a href="/piqa-web/">PIQA</a></li><li><a href="https://www.cs.washington.edu/research/nlp">University of Washington</a></li></ul></div></div></div></nav><script src="/piqa-web/bower_components/jquery/dist/jquery.min.js"></script><script src="/piqa-web/bower_components/bootstrap/dist/js/bootstrap.min.js"></script></body></html>